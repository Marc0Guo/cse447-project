{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "header"
   },
   "source": [
    "# N-gram Character Prediction with Kneser-Ney Smoothing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup"
   },
   "source": [
    "## 1. Setup and Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install_deps"
   },
   "outputs": [],
   "source": [
    "# Install required dependencies\n",
    "!pip install -q datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "upload_code"
   },
   "source": [
    "## 2. Upload Code Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "create_dirs"
   },
   "outputs": [],
   "source": [
    "# Create necessary directories\n",
    "!mkdir -p src work output\n",
    "\n",
    "# Upload your NGram_Model.py file\n",
    "from google.colab import files\n",
    "\n",
    "print(\"Please upload your NGram_Model.py file:\")\n",
    "uploaded = files.upload()\n",
    "\n",
    "# Move to src directory\n",
    "!mv NGram_Model.py src/NGram_Model.py\n",
    "print(\"File uploaded to src/NGram_Model.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "check_file"
   },
   "source": [
    "Verify the file is in place:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "verify_file"
   },
   "outputs": [],
   "source": [
    "!ls -lh src/NGram_Model.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "train_section"
   },
   "source": [
    "## 3. Train the Model\n",
    "\n",
    "Train the N-gram model on Wikitext-103 dataset. This will take about 10-20 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "train_model"
   },
   "outputs": [],
   "source": [
    "# Train with default parameters (n=4, vocab_size=1000)\n",
    "!python src/NGram_Model.py train \\\n",
    "    --work_dir work \\\n",
    "    --n 4 \\\n",
    "    --vocab_size 1000 \\\n",
    "    --discount 0.75"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "train_custom"
   },
   "source": [
    "### Alternative: Quick Training (for testing)\n",
    "\n",
    "If you want faster training, use smaller parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "train_fast"
   },
   "outputs": [],
   "source": [
    "# Faster training with smaller model (uncomment to use)\n",
    "# !python src/NGram_Model.py train \\\n",
    "#     --work_dir work \\\n",
    "#     --n 3 \\\n",
    "#     --vocab_size 500 \\\n",
    "#     --discount 0.75"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "check_checkpoint"
   },
   "source": [
    "Check the trained model checkpoint:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ls_checkpoint"
   },
   "outputs": [],
   "source": [
    "!ls -lh work/model.checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eval_section"
   },
   "source": [
    "## 4. Quick Evaluation (1000 samples)\n",
    "\n",
    "First, let's do a quick evaluation on 1000 samples from the validation set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eval_quick"
   },
   "outputs": [],
   "source": [
    "!python src/NGram_Model.py evaluate \\\n",
    "    --work_dir work \\\n",
    "    --split validation \\\n",
    "    --max_samples 1000 \\\n",
    "    --verbose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eval_full"
   },
   "source": [
    "## 5. Full Validation Evaluation\n",
    "\n",
    "Evaluate on the complete validation set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eval_validation"
   },
   "outputs": [],
   "source": [
    "!python src/NGram_Model.py evaluate \\\n",
    "    --work_dir work \\\n",
    "    --split validation \\\n",
    "    --verbose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eval_test"
   },
   "source": [
    "## 6. Test Set Evaluation\n",
    "\n",
    "Final evaluation on the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eval_test_run"
   },
   "outputs": [],
   "source": [
    "!python src/NGram_Model.py evaluate \\\n",
    "    --work_dir work \\\n",
    "    --split test \\\n",
    "    --verbose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "generate_pred"
   },
   "source": [
    "## 7. Generate Predictions File\n",
    "\n",
    "Generate predictions on test set and save to file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "test_generate"
   },
   "outputs": [],
   "source": [
    "!python src/NGram_Model.py test \\\n",
    "    --work_dir work \\\n",
    "    --split test \\\n",
    "    --test_output output/predictions.txt\n",
    "\n",
    "# Show first 10 predictions\n",
    "!head -10 output/predictions.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "download_section"
   },
   "source": [
    "## 8. Download Results\n",
    "\n",
    "Download the trained model and predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "download_files"
   },
   "outputs": [],
   "source": [
    "# Create a zip file with model and predictions\n",
    "!zip -r results.zip work/ output/\n",
    "\n",
    "# Download the zip file\n",
    "from google.colab import files\n",
    "files.download('results.zip')\n",
    "\n",
    "print(\"âœ“ Downloaded results.zip containing:\")\n",
    "print(\"  - work/model.checkpoint (trained model)\")\n",
    "print(\"  - output/predictions.txt (test predictions)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "interactive_section"
   },
   "source": [
    "## 9. Interactive Testing\n",
    "\n",
    "Test the model interactively with custom input:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "test_interactive"
   },
   "outputs": [],
   "source": [
    "# Load the model and test with custom inputs\n",
    "import sys\n",
    "sys.path.append('src')\n",
    "\n",
    "from NGram_Model import MyModel\n",
    "\n",
    "# Load trained model\n",
    "print(\"Loading model...\")\n",
    "model = MyModel.load('work')\n",
    "print(f\"Model loaded: n={model.n}, vocab_size={len(model.vocab) if model.vocab else 'unlimited'}\")\n",
    "\n",
    "# Test with some example inputs\n",
    "test_inputs = [\n",
    "    \"Hello, my name is\",\n",
    "    \"The quick brown\",\n",
    "    \"Machine learning is\",\n",
    "    \"I love\",\n",
    "    \"Python is a programming\",\n",
    "]\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Testing predictions:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for inp in test_inputs:\n",
    "    preds = model._get_top_candidates(inp)\n",
    "    print(f\"\\nInput: '{inp}'\")\n",
    "    print(f\"Top 3 predictions: {preds[0]!r}, {preds[1]!r}, {preds[2]!r}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "custom_test"
   },
   "source": [
    "### Test with Your Own Input\n",
    "\n",
    "Try the model with your custom text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "custom_input"
   },
   "outputs": [],
   "source": [
    "# Enter your own text to test\n",
    "custom_text = \"Once upon a time\"  # Change this!\n",
    "\n",
    "predictions = model._get_top_candidates(custom_text)\n",
    "print(f\"Input: '{custom_text}'\")\n",
    "print(f\"Top 3 next character predictions: {predictions}\")\n",
    "print(f\"As string: '{predictions[0]}{predictions[1]}{predictions[2]}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "analysis_section"
   },
   "source": [
    "## 10. Model Analysis\n",
    "\n",
    "Analyze the trained model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "analyze_model"
   },
   "outputs": [],
   "source": [
    "# Show model statistics\n",
    "print(\"Model Statistics:\")\n",
    "print(\"=\"*60)\n",
    "print(f\"N-gram order: {model.n}\")\n",
    "print(f\"Vocabulary size: {len(model.vocab) if model.vocab else 'unlimited'}\")\n",
    "print(f\"Discount parameter: {model.discount}\")\n",
    "print(f\"Total unique contexts: {len(model.ngram_counts)}\")\n",
    "print(f\"Total unigram count: {sum(model.unigram_counts.values())}\")\n",
    "print(f\"Total continuation count: {model.total_continuation}\")\n",
    "\n",
    "# Show most common characters\n",
    "print(\"\\nTop 20 most common characters:\")\n",
    "print(\"=\"*60)\n",
    "for char, count in model.unigram_counts.most_common(20):\n",
    "    char_display = repr(char) if char != ' ' else \"'space'\"\n",
    "    print(f\"{char_display:>10s}: {count:>10,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "notes_section"
   },
   "source": [
    "## Notes\n",
    "\n",
    "### Model Parameters:\n",
    "- **n=4**: 4-gram model (uses up to 3 characters of context)\n",
    "- **vocab_size=1000**: Keep only top 1000 most frequent characters\n",
    "- **discount=0.75**: Kneser-Ney discount parameter\n",
    "\n",
    "### Performance Tips:\n",
    "- **Faster training**: Use `--n 3 --vocab_size 500`\n",
    "- **Better accuracy**: Use `--n 4 --vocab_size 2000`\n",
    "- **Quick testing**: Use `--max_samples 1000` for evaluation\n",
    "\n",
    "### Colab Tips:\n",
    "- **Save your work**: Download results.zip before closing\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "None",
  "colab": {
   "collapsed_sections": [],
   "name": "run_model.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
